
<p align="center">
	<img src="images/image1.jpg" width="400" alt="Image 1"/>
</p>

---
# Self-Optimizing Load Balancer
### **ğŸ”¹ Overview**
The **AI-Driven Self-Optimizing Load Balancer** is a high-performance, **self-learning** traffic distribution system designed to optimize request routing based on **server health, request complexity, and AI-predicted response times**. Unlike traditional round-robin or least-connections load balancers, this system leverages **machine learning** to dynamically predict and adjust traffic distribution in real time.

### **âœ… Key Features**
- **Smart Traffic Routing:** Routes requests based on real-time server health, request weight, and ML-predicted load.  
- **AI-Driven Load Balancing:** Uses an **ONNX-based reinforcement learning model** to distribute traffic dynamically.  
- **Automated Failover:** Detects failing servers and reroutes traffic before they crash.  
- **Metrics-Driven Decision Making:** Collects real-time **Prometheus-based** server metrics for performance tracking.  
- **Scalable & Resilient Architecture:** Designed with **Kubernetes, NGINX, TimescaleDB, and Echo (Go)** for optimal performance.  
- **Observability & Logging:** Uses **Grafana, Loki, and Jaeger** for deep monitoring, logging, and tracing.  

---

## **ğŸ›  System Architecture**
### **ğŸ“Œ High-Level Workflow**
```plaintext
          â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
          â”‚           ğŸŒ Clients (Users)             â”‚
          â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â”‚
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚  API Gateway (NGINX)      â”‚  â† Reverse Proxy
        â”‚  - Rate Limiting          â”‚
        â”‚  - Initial LB (Lua)       â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â”‚
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚ Load Balancer (Go + Echo) â”‚  â† Main Traffic Router
        â”‚ - Fetches Server Health   â”‚
        â”‚ - Calls ML Model for LB   â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                  â”‚          â”‚
 â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
 â”‚ ML Model Service (ONNX)  â”‚   â”‚  Metrics Collector       â”‚
 â”‚ - Predicts Best Server   â”‚   â”‚  (Prometheus, Timescale) â”‚
 â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                  â”‚          â”‚
 â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
 â”‚   Backend Services       â”‚   â”‚  Observability Stack     â”‚
 â”‚ - API Services           â”‚   â”‚ (Grafana, Loki, Jaeger)  â”‚
 â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### **ğŸ”¹ Core Components**
1. **ğŸŒ Clients (Users)**
   - Users send requests to the system via a web browser, mobile app, or API client.

2. **ğŸ”— API Gateway (NGINX + OpenResty)**
   - Acts as the **entry point** for incoming traffic.  
   - Implements **rate limiting** and **initial load balancing** (via Lua scripting).  

3. **âš– Load Balancer (Go + Echo)**
   - The **main traffic router** that assigns requests to the best server.  
   - Fetches real-time **server health & load metrics**.  
   - Calls the **AI Model (ONNX-based RL model)** for optimal traffic distribution.  

4. **ğŸ§  ML Model Service (ONNX)**
   - Uses **reinforcement learning (RL)** to predict the most efficient load distribution.  
   - Analyzes **historical traffic, server performance, and request weight**.  

5. **ğŸ“Š Metrics Collector (Prometheus, TimescaleDB)**
   - Stores **server response times, error rates, request loads**, and more.  
   - Helps the **ML model improve accuracy over time**.  

6. **ğŸ–¥ Backend Services**
   - Actual **API services and microservices** handling user requests.  
   - Includes databases and any **application logic**.  

7. **ğŸ” Observability Stack (Grafana, Loki, Jaeger)**
   - **Grafana**: Real-time visualization of system health.  
   - **Loki**: Centralized logging system.  
   - **Jaeger**: Distributed tracing to track request paths.  

---

## **ğŸ›  Tech Stack**
| **Component**  | **Technology Used**  |
|---------------|---------------------|
| **API Gateway**  | NGINX, OpenResty (Lua)  |
| **Load Balancer**  | Go, Echo framework  |
| **Machine Learning**  | ONNX, Reinforcement Learning  |
| **Database**  | MySQL, TimescaleDB  |
| **Metrics & Monitoring**  | Prometheus, Grafana  |
| **Logging & Tracing**  | Loki, Jaeger  |
| **Containerization**  | Docker, Kubernetes  |
| **CI/CD**  | GitHub Actions, ArgoCD  |

---

## **ğŸš€ How to Launch**
### **1ï¸âƒ£ Clone the Repository**
```bash
git clone https://github.com/your-repo/ai-load-balancer.git
cd ai-load-balancer
```

### **2ï¸âƒ£ Set Up Environment Variables**
Modify `.env` to match your setup:
```plaintext
APP_PORT=8080
DB_HOST=localhost
DB_PORT=5432
DB_USER=admin
DB_PASSWORD=securepassword
ML_SERVER_HOST=http://ml-service
PROMETHEUS_URL=http://prometheus:9090
```

### **3ï¸âƒ£ Start Services with Docker Compose**
```bash
docker-compose up -d
```

### **4ï¸âƒ£ Deploy to Kubernetes**
```bash
kubectl apply -f deployments/k8s/
```

### **5ï¸âƒ£ Verify Deployment**
- Check running services:
  ```bash
  kubectl get pods
  ```
- Open **Grafana Dashboard** to view real-time metrics.

---

## **ğŸ”¹ API Endpoints**
| **Method** | **Endpoint** | **Description** |
|------------|-------------|-----------------|
| `GET` | `/api/health` | Health check for load balancer |
| `POST` | `/api/route` | Routes request to best server |
| `GET` | `/api/metrics` | Fetches current server stats |

---

## **ğŸ” Monitoring & Debugging**
- **Metrics Dashboard**: `http://localhost:3000` (Grafana)  
- **Logs**: `docker logs -f <container_id>`  
- **Prometheus Metrics**: `http://localhost:9090/targets`  

---

## **ğŸ“Œ Next Steps**
1. **Integrate Auto-Scaling with Kubernetes (HPA)**  
2. **Enhance AI Model with Federated Learning**  
3. **Deploy in Production with Load Testing**  

---

## **ğŸ’¡ Why This Load Balancer is Unique?**
âœ… **Self-Learning AI Model:** Optimizes itself based on real-time performance.  
âœ… **Multi-Layer Traffic Management:** Combines **NGINX, Go, and ML** for **fine-grained** request handling.  
âœ… **Resilient & Scalable:** Supports **microservices, failover handling, and observability tools**.  


```plaintext
ğŸ“‚ ai-load-balancer/
â”‚â”€â”€ ğŸ“‚ .github/                   # GitHub Actions (CI/CD) workflows
â”‚   â”œâ”€â”€ workflows/
â”‚   â”‚   â”œâ”€â”€ ci.yml                # CI: Build, test, lint
â”‚   â”‚   â”œâ”€â”€ cd.yml                # CD: Deploy with ArgoCD/K8s
â”‚â”€â”€ ğŸ“‚ backend/                   # Backend system (Load Balancer, API, DB)
â”‚   â”œâ”€â”€ ğŸ“‚ cmd/                    # Application entry points
â”‚   â”‚   â”œâ”€â”€ api/                   # Main API binary
â”‚   â”‚   â”‚   â”œâ”€â”€ main.go            # Initializes API server
â”‚   â”œâ”€â”€ ğŸ“‚ configs/                 # Configuration files
â”‚   â”‚   â”œâ”€â”€ config.yaml            # Backend config
â”‚   â”‚   â”œâ”€â”€ nginx.conf             # NGINX reverse proxy config
â”‚   â”œâ”€â”€ ğŸ“‚ internal/                # Core backend logic
â”‚   â”‚   â”œâ”€â”€ ğŸ“‚ api/                 # API handlers
â”‚   â”‚   â”‚   â”œâ”€â”€ handlers.go        # Request handlers
â”‚   â”‚   â”‚   â”œâ”€â”€ middleware.go      # Middleware (logging, auth, etc.)
â”‚   â”‚   â”‚   â”œâ”€â”€ router.go          # Route definitions (Echo)
â”‚   â”‚   â”œâ”€â”€ ğŸ“‚ loadbalancer/        # Load balancing logic
â”‚   â”‚   â”‚   â”œâ”€â”€ balancer.go        # Core balancing logic
â”‚   â”‚   â”‚   â”œâ”€â”€ strategies.go      # Round Robin, Least Connections, etc.
â”‚   â”‚   â”œâ”€â”€ ğŸ“‚ models/              # Data structures
â”‚   â”‚   â”‚   â”œâ”€â”€ server.go          # Server status & metadata
â”‚   â”‚   â”‚   â”œâ”€â”€ request.go         # API request/response models
â”‚   â”‚   â”œâ”€â”€ ğŸ“‚ metrics/             # Monitoring and metrics collection
â”‚   â”‚   â”‚   â”œâ”€â”€ collector.go       # Fetches Prometheus metrics
â”‚   â”‚   â”‚   â”œâ”€â”€ storage.go         # Stores server stats in TimescaleDB
â”‚   â”‚   â”œâ”€â”€ ğŸ“‚ database/            # Database connections & queries
â”‚   â”‚   â”‚   â”œâ”€â”€ db.go              # postgreSQL/TimescaleDB connection
â”‚   â”‚   â”‚   â”œâ”€â”€ migrations.sql     # DB schema migrations
â”‚   â”‚   â”œâ”€â”€ ğŸ“‚ utils/               # Utility functions
â”‚   â”‚   â”‚   â”œâ”€â”€ logger.go          # Structured logging
â”‚   â”‚   â”‚   â”œâ”€â”€ config.go          # Reads app configs
â”‚â”€â”€ ğŸ“‚ ml/                         # AI Model for Load Balancing
â”‚   â”œâ”€â”€ ğŸ“‚ model-server/            # Model inference server
â”‚   â”‚   â”œâ”€â”€ main.go                # Runs ONNX-based inference service
â”‚   â”œâ”€â”€ ğŸ“‚ training/                # Model training scripts
â”‚   â”‚   â”œâ”€â”€ train_model.py         # AI model training script
â”‚   â”‚   â”œâ”€â”€ data_preprocessing.py  # Data cleaning & processing
â”‚   â”œâ”€â”€ ğŸ“‚ models/                  # Trained models
â”‚   â”‚   â”œâ”€â”€ load_balancer.onnx     # Pre-trained model file
â”‚   â”œâ”€â”€ ğŸ“‚ utils/                   # ML utilities
â”‚   â”‚   â”œâ”€â”€ inference.py           # Runs model inference
â”‚   â”‚   â”œâ”€â”€ trainer.py             # Model training functions
â”‚â”€â”€ ğŸ“‚ deployments/                 # Kubernetes & Helm deployment scripts
â”‚   â”œâ”€â”€ ğŸ“‚ k8s/                     # K8s manifests
â”‚   â”‚   â”œâ”€â”€ backend-deployment.yaml # Backend service deployment
â”‚   â”‚   â”œâ”€â”€ ml-deployment.yaml      # ML service deployment
â”‚   â”‚   â”œâ”€â”€ service.yaml            # Service definitions
â”‚   â”œâ”€â”€ ğŸ“‚ helm/                    # Helm charts for deployment
â”‚â”€â”€ ğŸ“‚ migrations/                  # Database migration scripts
â”‚   â”œâ”€â”€ 001_create_tables.sql       # Initial database schema
â”‚â”€â”€ ğŸ“‚ scripts/                      # Automation scripts
â”‚   â”œâ”€â”€ build.sh                    # Builds the project
â”‚   â”œâ”€â”€ run.sh                      # Starts the service locally
â”‚â”€â”€ ğŸ“‚ test/                         # Unit and integration tests
â”‚   â”œâ”€â”€ api_test.go                  # API tests
â”‚   â”œâ”€â”€ loadbalancer_test.go         # Load balancer logic tests
â”‚   â”œâ”€â”€ ml_test.py                   # AI model tests
â”‚â”€â”€ ğŸ“‚ docs/                         # Documentation
â”‚   â”œâ”€â”€ README.md                    # Project overview
â”‚   â”œâ”€â”€ API.md                        # API documentation
â”‚   â”œâ”€â”€ ARCHITECTURE.md               # System architecture details
â”‚â”€â”€ .env                              # Environment variables
â”‚â”€â”€ .gitignore                        # Ignore files
â”‚â”€â”€ docker-compose.yml                # Docker Compose setup for local dev
â”‚â”€â”€ Dockerfile                        # API containerization
â”‚â”€â”€ go.mod                            # Go module dependencies
â”‚â”€â”€ go.sum                            # Go module checksum
â”‚â”€â”€ Taskfile.yml                      # Task automation
```
